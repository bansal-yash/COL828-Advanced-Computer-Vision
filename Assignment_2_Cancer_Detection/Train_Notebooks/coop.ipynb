{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:31.486418Z",
     "iopub.status.busy": "2025-11-20T18:10:31.485940Z",
     "iopub.status.idle": "2025-11-20T18:10:43.990546Z",
     "shell.execute_reply": "2025-11-20T18:10:43.989676Z",
     "shell.execute_reply.started": "2025-11-20T18:10:31.486385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:43.992358Z",
     "iopub.status.busy": "2025-11-20T18:10:43.991866Z",
     "iopub.status.idle": "2025-11-20T18:10:43.996078Z",
     "shell.execute_reply": "2025-11-20T18:10:43.995300Z",
     "shell.execute_reply.started": "2025-11-20T18:10:43.992339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/kaggle/input/mammography\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:43.996909Z",
     "iopub.status.busy": "2025-11-20T18:10:43.996690Z",
     "iopub.status.idle": "2025-11-20T18:10:44.020423Z",
     "shell.execute_reply": "2025-11-20T18:10:44.019713Z",
     "shell.execute_reply.started": "2025-11-20T18:10:43.996893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.data = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "        self.label_map = {\"BENIGN\": 0, \"MALIGNANT\": 1}\n",
    "        self.data[\"label\"] = self.data[\"pathology\"].map(self.label_map)\n",
    "\n",
    "        for col in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]:\n",
    "            if col in self.data.columns:\n",
    "                self.data[col] = self.data[col].fillna(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row[\"image_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        target_height, target_width = 981, 800\n",
    "        \n",
    "        image = image.resize((target_width, target_height), Image.BILINEAR)\n",
    "\n",
    "        scale_x = target_width / original_width\n",
    "        scale_y = target_height / original_height\n",
    "        \n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        \n",
    "        if label == 1:\n",
    "            scaled_xmin = row[\"xmin\"] * scale_x\n",
    "            scaled_ymin = row[\"ymin\"] * scale_y\n",
    "            scaled_xmax = row[\"xmax\"] * scale_x\n",
    "            scaled_ymax = row[\"ymax\"] * scale_y\n",
    "            \n",
    "            bbox_xywh = torch.tensor(\n",
    "                [\n",
    "                    scaled_xmin,\n",
    "                    scaled_ymin,\n",
    "                    scaled_xmax - scaled_xmin,\n",
    "                    scaled_ymax - scaled_ymin,\n",
    "                ],\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            annotations = {\n",
    "                \"image_id\": 0,\n",
    "                \"annotations\": [\n",
    "                    {\n",
    "                        \"bbox\": bbox_xywh,\n",
    "                        \"area\": float(bbox_xywh[2] * bbox_xywh[3]),\n",
    "                        \"category_id\": 0,\n",
    "                        \"iscrowd\": 0,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        else:\n",
    "            annotations = {\"image_id\": 0, \"annotations\": []}\n",
    "        \n",
    "        return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.022234Z",
     "iopub.status.busy": "2025-11-20T18:10:44.021996Z",
     "iopub.status.idle": "2025-11-20T18:10:44.039058Z",
     "shell.execute_reply": "2025-11-20T18:10:44.038410Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.022218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def grounding_dino_collate_fn(batch):\n",
    "    images, annotations = zip(*batch)\n",
    "    return list(images), list(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.039940Z",
     "iopub.status.busy": "2025-11-20T18:10:44.039776Z",
     "iopub.status.idle": "2025-11-20T18:10:44.055021Z",
     "shell.execute_reply": "2025-11-20T18:10:44.054477Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.039926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_train_dataloaders(train_name):\n",
    "    train_csv = f\"{DATASET_ROOT}/dataset_{train_name}/train/train.csv\"\n",
    "    train_img_dir = f\"{DATASET_ROOT}/dataset_{train_name}/train\"\n",
    "\n",
    "    train_full_df = pd.read_csv(train_csv)\n",
    "\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx = next(splitter.split(train_full_df, train_full_df[\"pathology\"]))\n",
    "\n",
    "    train_df = train_full_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = train_full_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MammographyDataset(train_df, train_img_dir)\n",
    "    val_dataset = MammographyDataset(val_df, train_img_dir)\n",
    "\n",
    "    class_counts = train_df[\"pathology\"].value_counts().to_dict()\n",
    "    total_samples = len(train_df)\n",
    "\n",
    "    weights = train_df[\"pathology\"].apply(lambda x: 1.0 / class_counts[x]).values\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=weights,\n",
    "        num_samples=total_samples,\n",
    "        replacement=True,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=2,\n",
    "        num_workers=4,\n",
    "        collate_fn=grounding_dino_collate_fn,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=grounding_dino_collate_fn,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.056222Z",
     "iopub.status.busy": "2025-11-20T18:10:44.055884Z",
     "iopub.status.idle": "2025-11-20T18:10:44.074808Z",
     "shell.execute_reply": "2025-11-20T18:10:44.074069Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.056199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_test_dataloaders():\n",
    "    datasets = [\"A\", \"B\", \"C\"]\n",
    "    test_loaders = []\n",
    "\n",
    "    for dataset in datasets:\n",
    "        test_csv = f\"{DATASET_ROOT}/dataset_{dataset}/test/test.csv\"\n",
    "        test_img_dir = f\"{DATASET_ROOT}/dataset_{dataset}/test\"\n",
    "\n",
    "        test_df = pd.read_csv(test_csv)\n",
    "        test_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in test_df.columns]\n",
    "\n",
    "        test_dataset = MammographyDataset(test_df, test_img_dir)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            collate_fn=grounding_dino_collate_fn,\n",
    "        )\n",
    "        test_loaders.append(test_loader)\n",
    "\n",
    "    return tuple(test_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.075943Z",
     "iopub.status.busy": "2025-11-20T18:10:44.075692Z",
     "iopub.status.idle": "2025-11-20T18:10:44.095461Z",
     "shell.execute_reply": "2025-11-20T18:10:44.094724Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.075919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    train_name,\n",
    "    num_epochs,\n",
    "    train_losses,\n",
    "    val_losses,\n",
    "    train_map50_scores,\n",
    "    val_map50_scores,\n",
    "    train_map75_scores,\n",
    "    val_map75_scores,\n",
    "    train_map_scores,\n",
    "    val_map_scores,\n",
    "):\n",
    "    epochs_range = range(1, num_epochs + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    axes[0, 0].plot(\n",
    "        epochs_range,\n",
    "        train_losses,\n",
    "        \"b-o\",\n",
    "        label=\"Training Loss\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[0, 0].plot(\n",
    "        epochs_range,\n",
    "        val_losses,\n",
    "        \"r-s\",\n",
    "        label=\"Validation Loss\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[0, 0].set_xlabel(\"Epoch\", fontsize=12)\n",
    "    axes[0, 0].set_ylabel(\"Loss (per sample)\", fontsize=12)\n",
    "    axes[0, 0].set_title(\n",
    "        f\"Training and Validation Loss - {train_name}\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    axes[0, 0].legend(fontsize=11)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0, 1].plot(\n",
    "        epochs_range,\n",
    "        train_map50_scores,\n",
    "        \"b-o\",\n",
    "        label=\"Training mAP@50\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[0, 1].plot(\n",
    "        epochs_range,\n",
    "        val_map50_scores,\n",
    "        \"r-s\",\n",
    "        label=\"Validation mAP@50\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[0, 1].set_xlabel(\"Epoch\", fontsize=12)\n",
    "    axes[0, 1].set_ylabel(\"mAP@50\", fontsize=12)\n",
    "    axes[0, 1].set_title(\n",
    "        f\"mAP@50 (IoU=0.5) - {train_name}\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    axes[0, 1].legend(fontsize=11)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1, 0].plot(\n",
    "        epochs_range,\n",
    "        train_map75_scores,\n",
    "        \"b-o\",\n",
    "        label=\"Training mAP@75\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[1, 0].plot(\n",
    "        epochs_range,\n",
    "        val_map75_scores,\n",
    "        \"r-s\",\n",
    "        label=\"Validation mAP@75\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[1, 0].set_xlabel(\"Epoch\", fontsize=12)\n",
    "    axes[1, 0].set_ylabel(\"mAP@75\", fontsize=12)\n",
    "    axes[1, 0].set_title(\n",
    "        f\"mAP@75 (IoU=0.75) - {train_name}\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    axes[1, 0].legend(fontsize=11)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1, 1].plot(\n",
    "        epochs_range,\n",
    "        train_map_scores,\n",
    "        \"b-o\",\n",
    "        label=\"Training mAP\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[1, 1].plot(\n",
    "        epochs_range,\n",
    "        val_map_scores,\n",
    "        \"r-s\",\n",
    "        label=\"Validation mAP\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[1, 1].set_xlabel(\"Epoch\", fontsize=12)\n",
    "    axes[1, 1].set_ylabel(\"mAP\", fontsize=12)\n",
    "    axes[1, 1].set_title(\n",
    "        f\"Mean Average Precision (mAP) - {train_name}\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    axes[1, 1].legend(fontsize=11)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"training_metrics_{train_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            \"epoch\": list(epochs_range),\n",
    "            \"train_loss\": train_losses,\n",
    "            \"val_loss\": val_losses,\n",
    "            \"train_map50\": train_map50_scores,\n",
    "            \"val_map50\": val_map50_scores,\n",
    "            \"train_map75\": train_map75_scores,\n",
    "            \"val_map75\": val_map75_scores,\n",
    "            \"train_map\": train_map_scores,\n",
    "            \"val_map\": val_map_scores,\n",
    "        }\n",
    "    )\n",
    "    metrics_df.to_csv(f\"training_metrics_{train_name}.csv\", index=False)\n",
    "    print(f\"\\n✓ Metrics saved to training_metrics_{train_name}.csv\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"FINAL TRAINING SUMMARY - {train_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Final Training Loss: {train_losses[-1]:.6f}\")\n",
    "    print(f\"Final Validation Loss: {val_losses[-1]:.6f}\")\n",
    "    print(f\"Final Training mAP@50: {train_map50_scores[-1]:.4f}\")\n",
    "    print(f\"Final Validation mAP@50: {val_map50_scores[-1]:.4f}\")\n",
    "    print(f\"Final Training mAP@75: {train_map75_scores[-1]:.4f}\")\n",
    "    print(f\"Final Validation mAP@75: {val_map75_scores[-1]:.4f}\")\n",
    "    print(f\"Final Training mAP: {train_map_scores[-1]:.4f}\")\n",
    "    print(f\"Final Validation mAP: {val_map_scores[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.096462Z",
     "iopub.status.busy": "2025-11-20T18:10:44.096213Z",
     "iopub.status.idle": "2025-11-20T18:10:44.116904Z",
     "shell.execute_reply": "2025-11-20T18:10:44.116118Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.096441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CoOpContext(nn.Module):\n",
    "    def __init__(self, device, processor, model, initial_prompt):\n",
    "        super().__init__()\n",
    "\n",
    "        tokens = processor.tokenizer(\n",
    "            initial_prompt, return_tensors=\"pt\", padding=False\n",
    "        ).to(device)\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_embeds = model.model.text_backbone.embeddings.word_embeddings(\n",
    "                input_ids\n",
    "            )\n",
    "\n",
    "        full_embeds = text_embeds[0, :, :]\n",
    "\n",
    "        self.all_embeddings = nn.Parameter(full_embeds.clone())\n",
    "        self.initial_token_ids = input_ids[0].clone()\n",
    "\n",
    "        seq_len = full_embeds.shape[0]\n",
    "        self.trainable_mask = torch.ones(seq_len, dtype=torch.bool)\n",
    "        self.trainable_mask[0] = False\n",
    "        self.trainable_mask[-2] = False\n",
    "        self.trainable_mask[-1] = False\n",
    "\n",
    "        def freeze_hook(grad):\n",
    "            mask = self.trainable_mask.unsqueeze(-1).to(grad.device)\n",
    "            return grad * mask\n",
    "\n",
    "        self.hook_handle = self.all_embeddings.register_hook(freeze_hook)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.all_embeddings\n",
    "\n",
    "    def parameters(self, recurse=True):\n",
    "        return super().parameters(recurse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.117964Z",
     "iopub.status.busy": "2025-11-20T18:10:44.117718Z",
     "iopub.status.idle": "2025-11-20T18:10:44.138790Z",
     "shell.execute_reply": "2025-11-20T18:10:44.137967Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.117943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def move_labels_to_device(labels, device):\n",
    "    new_labels = []\n",
    "    for lbl in labels:\n",
    "        new_lbl = {}\n",
    "        for k, v in lbl.items():\n",
    "            if torch.is_tensor(v):\n",
    "                new_lbl[k] = v.to(device)\n",
    "            else:\n",
    "                new_lbl[k] = v\n",
    "        new_labels.append(new_lbl)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.141662Z",
     "iopub.status.busy": "2025-11-20T18:10:44.141402Z",
     "iopub.status.idle": "2025-11-20T18:10:44.169230Z",
     "shell.execute_reply": "2025-11-20T18:10:44.168530Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.141638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_dataset(model, processor, train_name, num_epochs):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"#  TRAINING ON DATASET {train_name}\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "\n",
    "    train_loader, val_loader = create_train_dataloaders(train_name=train_name)\n",
    "\n",
    "    initial_prompt = \"malignant tumor cancer.\"\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Configuration\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Dataset           : {train_name}\")\n",
    "    print(f\"  Epochs            : {num_epochs}\")\n",
    "    print(f\"  Base Prompt       : '{initial_prompt}'\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    context_module = CoOpContext(\n",
    "        device=device,\n",
    "        processor=processor,\n",
    "        model=model,\n",
    "        initial_prompt=initial_prompt,\n",
    "    )\n",
    "\n",
    "    print(f\"  Initial Context Vector:\\n {context_module()}\\n\")\n",
    "    print(f\"  Context Vector Shape: {context_module().shape}\\n\")\n",
    "\n",
    "    lr = 5e-4\n",
    "    optimizer = optim.AdamW(context_module.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=num_epochs,\n",
    "        eta_min=1e-4\n",
    "    )\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_map50_scores = []\n",
    "    train_map75_scores = []\n",
    "    train_map_scores = []\n",
    "    val_map50_scores = []\n",
    "    val_map75_scores = []\n",
    "    val_map_scores = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    train_map_metric = MeanAveragePrecision(iou_thresholds=[0.5, 0.75]).to(device)\n",
    "    val_map_metric = MeanAveragePrecision(iou_thresholds=[0.5, 0.75]).to(device)\n",
    "\n",
    "    train_map_metric.warn_on_many_detections = False\n",
    "    val_map_metric.warn_on_many_detections = False\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  Epoch {epoch + 1}/{num_epochs} - Dataset {train_name}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        model.eval()\n",
    "        context_module.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_map_metric.reset()\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=\"  Training  \")\n",
    "        for images, annotations in train_pbar:\n",
    "            batch_size = len(images)\n",
    "            inputs = processor(\n",
    "                images=images, annotations=annotations, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            del inputs[\"pixel_mask\"]\n",
    "\n",
    "            context_expanded = context_module().unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            context_token_ids = context_module.initial_token_ids.unsqueeze(0).expand(\n",
    "                batch_size, -1\n",
    "            )\n",
    "\n",
    "            prompt_enc = {}\n",
    "            prompt_enc[\"input_ids\"] = context_token_ids\n",
    "            prompt_enc[\"inputs_embeds\"] = context_expanded\n",
    "            labels = move_labels_to_device(inputs[\"labels\"], device)\n",
    "            inputs[\"labels\"] = labels\n",
    "\n",
    "            inputs = inputs | prompt_enc\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss_dict = outputs.loss_dict\n",
    "            weight_dict = {\n",
    "                \"loss_ce\": 2.0,\n",
    "                \"loss_bbox\": model.config.bbox_loss_coefficient,\n",
    "                \"loss_giou\": model.config.giou_loss_coefficient,\n",
    "            }\n",
    "            enc_weight_dict = {k + \"_enc\": v for k, v in weight_dict.items()}\n",
    "            weight_dict.update(enc_weight_dict)\n",
    "            weight_dict[\"loss_ce_enc\"] = 0\n",
    "            weight_dict[\"loss_bbox_enc\"] = 0\n",
    "            weight_dict[\"loss_giou_enc\"] = 0\n",
    "            loss = sum(\n",
    "                loss_dict[k] * weight_dict[k]\n",
    "                for k in loss_dict.keys()\n",
    "                if k in weight_dict\n",
    "            )\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                target_sizes = [img.size[::-1] for img in images]\n",
    "                results = processor.post_process_grounded_object_detection(\n",
    "                    outputs,\n",
    "                    inputs.input_ids,\n",
    "                    threshold=0,\n",
    "                    text_threshold=0,\n",
    "                    target_sizes=target_sizes,\n",
    "                )\n",
    "\n",
    "                preds = []\n",
    "                targets = []\n",
    "\n",
    "                for res, anno in zip(results, annotations):\n",
    "                    preds.append(\n",
    "                        {\n",
    "                            \"boxes\": res[\"boxes\"],\n",
    "                            \"scores\": res[\"scores\"],\n",
    "                            \"labels\": torch.zeros(\n",
    "                                len(res[\"boxes\"]), dtype=torch.long, device=device\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    if len(anno[\"annotations\"]) > 0:\n",
    "                        gt_boxes = torch.stack([a[\"bbox\"] for a in anno[\"annotations\"]])\n",
    "                        gt_boxes_xyxy = torch.zeros_like(gt_boxes)\n",
    "                        gt_boxes_xyxy[:, 0] = gt_boxes[:, 0]\n",
    "                        gt_boxes_xyxy[:, 1] = gt_boxes[:, 1]\n",
    "                        gt_boxes_xyxy[:, 2] = gt_boxes[:, 0] + gt_boxes[:, 2]\n",
    "                        gt_boxes_xyxy[:, 3] = gt_boxes[:, 1] + gt_boxes[:, 3]\n",
    "\n",
    "                        targets.append(\n",
    "                            {\n",
    "                                \"boxes\": gt_boxes_xyxy.to(device),\n",
    "                                \"labels\": torch.zeros(\n",
    "                                    len(gt_boxes), dtype=torch.long, device=device\n",
    "                                ),\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        targets.append(\n",
    "                            {\n",
    "                                \"boxes\": torch.empty((0, 4), device=device),\n",
    "                                \"labels\": torch.empty(\n",
    "                                    0, dtype=torch.long, device=device\n",
    "                                ),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                train_map_metric.update(preds, targets)\n",
    "\n",
    "            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        train_metrics = train_map_metric.compute()\n",
    "        train_map50_scores.append(train_metrics[\"map_50\"].item())\n",
    "        train_map75_scores.append(train_metrics[\"map_75\"].item())\n",
    "        train_map_scores.append(train_metrics[\"map\"].item())\n",
    "\n",
    "        print(f\"\\n  Training Metrics:\")\n",
    "        print(f\"    Loss         : {avg_train_loss:.6f}\")\n",
    "        print(f\"    mAP@50       : {train_metrics['map_50']:.4f}\")\n",
    "        print(f\"    mAP@75       : {train_metrics['map_75']:.4f}\")\n",
    "        print(f\"    mAP (Overall): {train_metrics['map']:.4f}\\n\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model.eval()\n",
    "        context_module.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_map_metric.reset()\n",
    "\n",
    "        val_pbar = tqdm(val_loader, desc=\"  Validation\")\n",
    "        with torch.no_grad():\n",
    "            for images, annotations in val_pbar:\n",
    "                batch_size = len(images)\n",
    "                inputs = processor(\n",
    "                    images=images, annotations=annotations, return_tensors=\"pt\"\n",
    "                ).to(device)\n",
    "                del inputs[\"pixel_mask\"]\n",
    "\n",
    "                context_expanded = (\n",
    "                    context_module().unsqueeze(0).expand(batch_size, -1, -1)\n",
    "                )\n",
    "                context_token_ids = context_module.initial_token_ids.unsqueeze(\n",
    "                    0\n",
    "                ).expand(batch_size, -1)\n",
    "\n",
    "                prompt_enc = {}\n",
    "                prompt_enc[\"input_ids\"] = context_token_ids\n",
    "                prompt_enc[\"inputs_embeds\"] = context_expanded\n",
    "                labels = move_labels_to_device(inputs[\"labels\"], device)\n",
    "                inputs[\"labels\"] = labels\n",
    "\n",
    "                inputs = inputs | prompt_enc\n",
    "\n",
    "                outputs = model(**inputs)\n",
    "                loss = outputs.loss\n",
    "                loss_dict = outputs.loss_dict\n",
    "                weight_dict = {\n",
    "                    \"loss_ce\": 2.0,\n",
    "                    \"loss_bbox\": model.config.bbox_loss_coefficient,\n",
    "                    \"loss_giou\": model.config.giou_loss_coefficient,\n",
    "                }\n",
    "                enc_weight_dict = {k + \"_enc\": v for k, v in weight_dict.items()}\n",
    "                weight_dict.update(enc_weight_dict)\n",
    "                weight_dict[\"loss_ce_enc\"] = 0\n",
    "                weight_dict[\"loss_bbox_enc\"] = 0\n",
    "                weight_dict[\"loss_giou_enc\"] = 0\n",
    "                loss = sum(\n",
    "                    loss_dict[k] * weight_dict[k]\n",
    "                    for k in loss_dict.keys()\n",
    "                    if k in weight_dict\n",
    "                )\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                target_sizes = [img.size[::-1] for img in images]\n",
    "                results = processor.post_process_grounded_object_detection(\n",
    "                    outputs,\n",
    "                    inputs.input_ids,\n",
    "                    threshold=0,\n",
    "                    text_threshold=0,\n",
    "                    target_sizes=target_sizes,\n",
    "                )\n",
    "\n",
    "                preds = []\n",
    "                targets = []\n",
    "\n",
    "                for res, anno in zip(results, annotations):\n",
    "                    preds.append(\n",
    "                        {\n",
    "                            \"boxes\": res[\"boxes\"],\n",
    "                            \"scores\": res[\"scores\"],\n",
    "                            \"labels\": torch.zeros(\n",
    "                                len(res[\"boxes\"]), dtype=torch.long, device=device\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    if len(anno[\"annotations\"]) > 0:\n",
    "                        gt_boxes = torch.stack([a[\"bbox\"] for a in anno[\"annotations\"]])\n",
    "                        gt_boxes_xyxy = torch.zeros_like(gt_boxes)\n",
    "                        gt_boxes_xyxy[:, 0] = gt_boxes[:, 0]\n",
    "                        gt_boxes_xyxy[:, 1] = gt_boxes[:, 1]\n",
    "                        gt_boxes_xyxy[:, 2] = gt_boxes[:, 0] + gt_boxes[:, 2]\n",
    "                        gt_boxes_xyxy[:, 3] = gt_boxes[:, 1] + gt_boxes[:, 3]\n",
    "\n",
    "                        targets.append(\n",
    "                            {\n",
    "                                \"boxes\": gt_boxes_xyxy.to(device),\n",
    "                                \"labels\": torch.zeros(\n",
    "                                    len(gt_boxes), dtype=torch.long, device=device\n",
    "                                ),\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        targets.append(\n",
    "                            {\n",
    "                                \"boxes\": torch.empty((0, 4), device=device),\n",
    "                                \"labels\": torch.empty(\n",
    "                                    0, dtype=torch.long, device=device\n",
    "                                ),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                val_map_metric.update(preds, targets)\n",
    "\n",
    "                val_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        val_metrics = val_map_metric.compute()\n",
    "        val_map50_scores.append(val_metrics[\"map_50\"].item())\n",
    "        val_map75_scores.append(val_metrics[\"map_75\"].item())\n",
    "        val_map_scores.append(val_metrics[\"map\"].item())\n",
    "\n",
    "        print(f\"\\n  Validation Metrics:\")\n",
    "        print(f\"    Loss         : {avg_val_loss:.6f}\")\n",
    "        print(f\"    mAP@50       : {val_metrics['map_50']:.4f}\")\n",
    "        print(f\"    mAP@75       : {val_metrics['map_75']:.4f}\")\n",
    "        print(f\"    mAP (Overall): {val_metrics['map']:.4f}\\n\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"context_vectors\": context_module.all_embeddings.data.clone(),\n",
    "                },\n",
    "                f\"best_context_vectors_{train_name}.pth\",\n",
    "            )\n",
    "\n",
    "            print(f\"  {'*'*66}\")\n",
    "            print(f\"  *** BEST MODEL SAVED! (Val Loss: {best_val_loss:.6f}) ***\")\n",
    "            print(f\"  {'*'*66}\\n\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Training Complete - Dataset {train_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Best Validation Loss: {best_val_loss:.6f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    plot_metrics(\n",
    "        train_name,\n",
    "        num_epochs,\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "        train_map50_scores,\n",
    "        val_map50_scores,\n",
    "        train_map75_scores,\n",
    "        val_map75_scores,\n",
    "        train_map_scores,\n",
    "        val_map_scores,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.170356Z",
     "iopub.status.busy": "2025-11-20T18:10:44.170117Z",
     "iopub.status.idle": "2025-11-20T18:10:44.189845Z",
     "shell.execute_reply": "2025-11-20T18:10:44.188917Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.170341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_one(model, processor, context_module, test_loader, dataset_name):\n",
    "    model.eval()\n",
    "    context_module.eval()\n",
    "\n",
    "    test_map_metric = MeanAveragePrecision(iou_thresholds=[0.5, 0.75]).to(device)\n",
    "    test_map_metric.warn_on_many_detections = False\n",
    "    \n",
    "    test_map_metric.reset()\n",
    "\n",
    "    total_test_loss = 0.0\n",
    "\n",
    "    test_pbar = tqdm(test_loader, desc=f\"Testing {dataset_name}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, annotations in test_pbar:\n",
    "            batch_size = len(images)\n",
    "\n",
    "            inputs = processor(\n",
    "                images=images, annotations=annotations, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            del inputs[\"pixel_mask\"]\n",
    "\n",
    "            context_expanded = context_module().unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            context_token_ids = context_module.initial_token_ids.unsqueeze(0).expand(\n",
    "                batch_size, -1\n",
    "            )\n",
    "\n",
    "            prompt_enc = {}\n",
    "            prompt_enc[\"input_ids\"] = context_token_ids\n",
    "            prompt_enc[\"inputs_embeds\"] = context_expanded\n",
    "\n",
    "            labels = move_labels_to_device(inputs[\"labels\"], device)\n",
    "            inputs[\"labels\"] = labels\n",
    "\n",
    "            inputs = inputs | prompt_enc\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss_dict = outputs.loss_dict\n",
    "\n",
    "            weight_dict = {\n",
    "                \"loss_ce\": 2.0,\n",
    "                \"loss_bbox\": model.config.bbox_loss_coefficient,\n",
    "                \"loss_giou\": model.config.giou_loss_coefficient,\n",
    "            }\n",
    "            enc_weight_dict = {k + \"_enc\": v for k, v in weight_dict.items()}\n",
    "            weight_dict.update(enc_weight_dict)\n",
    "            weight_dict[\"loss_ce_enc\"] = 0\n",
    "            weight_dict[\"loss_bbox_enc\"] = 0\n",
    "            weight_dict[\"loss_giou_enc\"] = 0\n",
    "\n",
    "            loss = sum(\n",
    "                loss_dict[k] * weight_dict[k]\n",
    "                for k in loss_dict.keys()\n",
    "                if k in weight_dict\n",
    "            )\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            target_sizes = [img.size[::-1] for img in images]\n",
    "            results = processor.post_process_grounded_object_detection(\n",
    "                outputs,\n",
    "                inputs.input_ids,\n",
    "                threshold=0,\n",
    "                text_threshold=0,\n",
    "                target_sizes=target_sizes,\n",
    "            )\n",
    "\n",
    "            preds = []\n",
    "            targets = []\n",
    "\n",
    "            for res, anno in zip(results, annotations):\n",
    "                preds.append(\n",
    "                    {\n",
    "                        \"boxes\": res[\"boxes\"],\n",
    "                        \"scores\": res[\"scores\"],\n",
    "                        \"labels\": torch.zeros(\n",
    "                            len(res[\"boxes\"]), dtype=torch.long, device=device\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if len(anno[\"annotations\"]) > 0:\n",
    "                    gt_boxes = torch.stack([a[\"bbox\"] for a in anno[\"annotations\"]])\n",
    "                    gt_boxes_xyxy = torch.zeros_like(gt_boxes)\n",
    "                    gt_boxes_xyxy[:, 0] = gt_boxes[:, 0]\n",
    "                    gt_boxes_xyxy[:, 1] = gt_boxes[:, 1]\n",
    "                    gt_boxes_xyxy[:, 2] = gt_boxes[:, 0] + gt_boxes[:, 2]\n",
    "                    gt_boxes_xyxy[:, 3] = gt_boxes[:, 1] + gt_boxes[:, 3]\n",
    "\n",
    "                    targets.append(\n",
    "                        {\n",
    "                            \"boxes\": gt_boxes_xyxy.to(device),\n",
    "                            \"labels\": torch.zeros(\n",
    "                                len(gt_boxes), dtype=torch.long, device=device\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    targets.append(\n",
    "                        {\n",
    "                            \"boxes\": torch.empty((0, 4), device=device),\n",
    "                            \"labels\": torch.empty(0, dtype=torch.long, device=device),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            test_map_metric.update(preds, targets)\n",
    "            test_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_metrics = test_map_metric.compute()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {dataset_name} Results\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Average Loss       : {avg_test_loss:.6f}\")\n",
    "    print(f\"  mAP@50            : {test_metrics['map_50']:.4f}\")\n",
    "    print(f\"  mAP@75            : {test_metrics['map_75']:.4f}\")\n",
    "    print(f\"  mAP (Overall)     : {test_metrics['map']:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.190821Z",
     "iopub.status.busy": "2025-11-20T18:10:44.190568Z",
     "iopub.status.idle": "2025-11-20T18:10:44.212115Z",
     "shell.execute_reply": "2025-11-20T18:10:44.211469Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.190800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_all_datasets(model, processor, train_name):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"#  TESTING MODEL - Trained on Dataset {train_name}\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "\n",
    "    initial_prompt = \"malignant tumor cancer.\"\n",
    "\n",
    "    context_module = CoOpContext(\n",
    "        device=device,\n",
    "        processor=processor,\n",
    "        model=model,\n",
    "        initial_prompt=initial_prompt,\n",
    "    )\n",
    "\n",
    "    def freeze_hook(grad):\n",
    "        mask = context_module.trainable_mask.unsqueeze(-1).to(grad.device)\n",
    "        return grad * mask\n",
    "\n",
    "    context_module.all_embeddings.register_hook(freeze_hook)\n",
    "\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Loading Best Context Vectors from Dataset {train_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        f\"best_context_vectors_{train_name}.pth\", map_location=device\n",
    "    )\n",
    "    context_module.all_embeddings.data = checkpoint[\"context_vectors\"]\n",
    "    print(f\"  ✓ Context vectors loaded successfully!\")\n",
    "    print(f\"  Context Vector: {context_module.all_embeddings}\")\n",
    "    print(f\"  Shape: {context_module.all_embeddings.shape}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    word_embeddings = model.model.text_backbone.embeddings.word_embeddings.weight\n",
    "    trainable_embeddings = context_module.all_embeddings[context_module.trainable_mask]\n",
    "    context_norm = F.normalize(trainable_embeddings, p=2, dim=1)\n",
    "    word_embeddings_norm = F.normalize(word_embeddings, p=2, dim=1)\n",
    "\n",
    "    similarities = torch.matmul(context_norm, word_embeddings_norm.T)\n",
    "\n",
    "    for i in range(len(trainable_embeddings)):\n",
    "        top_sims, top_indices = torch.topk(similarities[i], k=5)\n",
    "\n",
    "        print(f\"\\nTrainable Context Vector {i}:\")\n",
    "        for sim, idx in zip(top_sims, top_indices):\n",
    "            word = processor.tokenizer.decode([idx.item()])\n",
    "            print(f\"  {word} ({sim.item():.4f})\")\n",
    "\n",
    "    test_loader_1, test_loader_2, test_loader_3 = create_test_dataloaders()\n",
    "\n",
    "    test_one(\n",
    "        model, processor, context_module, test_loader_1, dataset_name=\"Test Dataset A\"\n",
    "    )\n",
    "    test_one(\n",
    "        model, processor, context_module, test_loader_2, dataset_name=\"Test Dataset B\"\n",
    "    )\n",
    "    test_one(\n",
    "        model, processor, context_module, test_loader_3, dataset_name=\"Test Dataset C\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.213009Z",
     "iopub.status.busy": "2025-11-20T18:10:44.212803Z",
     "iopub.status.idle": "2025-11-20T18:10:44.232094Z",
     "shell.execute_reply": "2025-11-20T18:10:44.231392Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.212994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_one(model, processor, context_module, test_loader):\n",
    "    count = 0\n",
    "    max_visualizations = 5\n",
    "\n",
    "    model.eval()\n",
    "    context_module.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, annotations in test_loader:\n",
    "            batch_size = len(images)\n",
    "\n",
    "            inputs = processor(\n",
    "                images=images, annotations=annotations, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            del inputs[\"pixel_mask\"]\n",
    "\n",
    "            context_expanded = context_module().unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            context_token_ids = context_module.initial_token_ids.unsqueeze(0).expand(\n",
    "                batch_size, -1\n",
    "            )\n",
    "\n",
    "            prompt_enc = {}\n",
    "            prompt_enc[\"input_ids\"] = context_token_ids\n",
    "            prompt_enc[\"inputs_embeds\"] = context_expanded\n",
    "\n",
    "            labels = move_labels_to_device(inputs[\"labels\"], device)\n",
    "            inputs[\"labels\"] = labels\n",
    "\n",
    "            inputs = inputs | prompt_enc\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            target_sizes = [img.size[::-1] for img in images]\n",
    "            results = processor.post_process_grounded_object_detection(\n",
    "                outputs,\n",
    "                inputs.input_ids,\n",
    "                threshold=0.1,\n",
    "                text_threshold=0.1,\n",
    "                target_sizes=target_sizes,\n",
    "            )\n",
    "\n",
    "            for img, res, lbls in zip(images, results, annotations):\n",
    "                boxes = res[\"boxes\"]\n",
    "                scores = res[\"scores\"]\n",
    "                text_labels = res.get(\"text_labels\", None)\n",
    "\n",
    "                k = 5\n",
    "                top_k = min(k, len(scores))\n",
    "                sorted_indices = scores.argsort(descending=True)[:top_k]\n",
    "                boxes = boxes[sorted_indices]\n",
    "                scores = scores[sorted_indices]\n",
    "                if text_labels is not None:\n",
    "                    text_labels = [text_labels[i] for i in sorted_indices.cpu().numpy()]\n",
    "\n",
    "                fig, (ax_img, ax_legend) = plt.subplots(\n",
    "                    1, 2, figsize=(16, 10), gridspec_kw={\"width_ratios\": [5, 1]}\n",
    "                )\n",
    "\n",
    "                ax_img.imshow(img)\n",
    "                ax_img.set_title(\n",
    "                    f\"Predictions: {len(boxes)} | GT: {len(lbls.get('annotations', []))}\",\n",
    "                    fontsize=14,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "                ax_img.axis(\"off\")\n",
    "\n",
    "                if \"annotations\" in lbls and len(lbls[\"annotations\"]) > 0:\n",
    "                    for ann in lbls[\"annotations\"]:\n",
    "                        bbox = ann[\"bbox\"].cpu().numpy()\n",
    "                        rect = patches.Rectangle(\n",
    "                            (bbox[0], bbox[1]),\n",
    "                            bbox[2],\n",
    "                            bbox[3],\n",
    "                            linewidth=3,\n",
    "                            edgecolor=\"red\",\n",
    "                            facecolor=\"none\",\n",
    "                        )\n",
    "                        ax_img.add_patch(rect)\n",
    "\n",
    "                        ax_img.text(\n",
    "                            bbox[0],\n",
    "                            bbox[1] - 5,\n",
    "                            \"GT\",\n",
    "                            color=\"white\",\n",
    "                            fontsize=10,\n",
    "                            fontweight=\"bold\",\n",
    "                            bbox=dict(\n",
    "                                facecolor=\"red\", alpha=0.9, edgecolor=\"none\", pad=1\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "                legend_text = []\n",
    "                for idx, (pred, score) in enumerate(zip(boxes, scores)):\n",
    "                    x1, y1, x2, y2 = pred.cpu().numpy()\n",
    "                    score_val = score.cpu().item()\n",
    "\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x1, y1),\n",
    "                        x2 - x1,\n",
    "                        y2 - y1,\n",
    "                        linewidth=3,\n",
    "                        edgecolor=\"blue\",\n",
    "                        facecolor=\"none\",\n",
    "                    )\n",
    "                    ax_img.add_patch(rect)\n",
    "\n",
    "                    ax_img.text(\n",
    "                        x1,\n",
    "                        y1 - 5,\n",
    "                        str(idx + 1),\n",
    "                        color=\"white\",\n",
    "                        fontsize=14,\n",
    "                        fontweight=\"bold\",\n",
    "                        bbox=dict(facecolor=\"blue\", alpha=0.9, edgecolor=\"none\", pad=2),\n",
    "                    )\n",
    "\n",
    "                    if text_labels is not None and idx < len(text_labels):\n",
    "                        label_str = text_labels[idx]\n",
    "                    else:\n",
    "                        label_str = \"N/A\"\n",
    "\n",
    "                    legend_text.append(\n",
    "                        f\"{idx + 1}. Score: {score_val:.3f}\\n   Label: {label_str}\"\n",
    "                    )\n",
    "\n",
    "                ax_legend.axis(\"off\")\n",
    "                ax_legend.set_xlim(0, 1)\n",
    "                ax_legend.set_ylim(0, 1)\n",
    "\n",
    "                ax_legend.text(\n",
    "                    0.05,\n",
    "                    0.95,\n",
    "                    \"Predictions\",\n",
    "                    fontsize=16,\n",
    "                    fontweight=\"bold\",\n",
    "                    verticalalignment=\"top\",\n",
    "                )\n",
    "\n",
    "                y_pos = 0.88\n",
    "                for text in legend_text:\n",
    "                    ax_legend.text(\n",
    "                        0.05,\n",
    "                        y_pos,\n",
    "                        text,\n",
    "                        fontsize=11,\n",
    "                        verticalalignment=\"top\",\n",
    "                        family=\"monospace\",\n",
    "                    )\n",
    "                    y_pos -= 0.12\n",
    "\n",
    "                if \"annotations\" in lbls and len(lbls[\"annotations\"]) > 0:\n",
    "                    gt_y_pos = y_pos - 0.05\n",
    "                    ax_legend.text(\n",
    "                        0.05,\n",
    "                        gt_y_pos,\n",
    "                        \"Ground Truth\",\n",
    "                        fontsize=14,\n",
    "                        fontweight=\"bold\",\n",
    "                        verticalalignment=\"top\",\n",
    "                        color=\"red\",\n",
    "                    )\n",
    "                    ax_legend.text(\n",
    "                        0.05,\n",
    "                        gt_y_pos - 0.08,\n",
    "                        f\"GT. {len(lbls['annotations'])} lesion(s)\",\n",
    "                        fontsize=11,\n",
    "                        verticalalignment=\"top\",\n",
    "                        family=\"monospace\",\n",
    "                        color=\"red\",\n",
    "                    )\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            count += 1\n",
    "            if count >= max_visualizations:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.233330Z",
     "iopub.status.busy": "2025-11-20T18:10:44.233070Z",
     "iopub.status.idle": "2025-11-20T18:10:44.251973Z",
     "shell.execute_reply": "2025-11-20T18:10:44.251287Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.233314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_all_datasets(model, processor, train_name):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"#  Visualize MODEL - Trained on Dataset {train_name}\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "\n",
    "    initial_prompt = \"malignant tumor cancer.\"\n",
    "\n",
    "    context_module = CoOpContext(\n",
    "        device=device,\n",
    "        processor=processor,\n",
    "        model=model,\n",
    "        initial_prompt=initial_prompt,\n",
    "    )\n",
    "\n",
    "    def freeze_hook(grad):\n",
    "        mask = context_module.trainable_mask.unsqueeze(-1).to(grad.device)\n",
    "        return grad * mask\n",
    "\n",
    "    context_module.all_embeddings.register_hook(freeze_hook)\n",
    "\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Loading Best Context Vectors from Dataset {train_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        f\"best_context_vectors_{train_name}.pth\", map_location=device\n",
    "    )\n",
    "    context_module.all_embeddings.data = checkpoint[\"context_vectors\"]\n",
    "    print(f\"  ✓ Context vectors loaded successfully!\")\n",
    "\n",
    "    test_loader_1, test_loader_2, test_loader_3 = create_test_dataloaders()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Visualizing Test Dataset A\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    visualize_one(model, processor, context_module, test_loader_1)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Visualizing Test Dataset B\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    visualize_one(model, processor, context_module, test_loader_2)\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Visualizing Test Dataset C\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    visualize_one(model, processor, context_module, test_loader_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:44.252948Z",
     "iopub.status.busy": "2025-11-20T18:10:44.252692Z",
     "iopub.status.idle": "2025-11-20T18:10:48.545760Z",
     "shell.execute_reply": "2025-11-20T18:10:48.544890Z",
     "shell.execute_reply.started": "2025-11-20T18:10:44.252927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"IDEA-Research/grounding-dino-base\"\n",
    "\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"#  INITIALIZING MODEL\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "print(f\"  Model: {model_id}\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "print(f\"  Model loaded and frozen successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:10:48.547039Z",
     "iopub.status.busy": "2025-11-20T18:10:48.546673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_one_dataset(model=model, processor=processor, train_name=\"A\", num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_all_datasets(model=model, processor=processor, train_name=\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_all_datasets(model=model, processor=processor, train_name=\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_one_dataset(model=model, processor=processor, train_name=\"B\", num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_all_datasets(model=model, processor=processor, train_name=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_all_datasets(model=model, processor=processor, train_name=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_one_dataset(model=model, processor=processor, train_name=\"C\", num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_all_datasets(model=model, processor=processor, train_name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_all_datasets(model=model, processor=processor, train_name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8550063,
     "sourceId": 13468902,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8661278,
     "sourceId": 13627453,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
